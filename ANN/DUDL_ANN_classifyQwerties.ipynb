{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DUDL_ANN_classifyQwerties.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: ANNs\n",
    "### LECTURE: ANN for classifying qwerties\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j7-LiwqUMGYL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create data\n",
    "\n",
    "nPerClust = 100\n",
    "blur = .01\n",
    "\n",
    "A = [  1, 1 ]\n",
    "B = [  5, 1 ]\n",
    "\n",
    "# generate data\n",
    "a = [ A[0]+np.random.randn(nPerClust)*blur , A[1]+np.random.randn(nPerClust)*blur ]\n",
    "b = [ B[0]+np.random.randn(nPerClust)*blur , B[1]+np.random.randn(nPerClust)*blur ]\n",
    "\n",
    "# true labels\n",
    "labels_np = np.vstack((np.zeros((nPerClust,1)),np.ones((nPerClust,1))))\n",
    "\n",
    "# concatanate into a matrix\n",
    "data_np = np.hstack((a,b)).T\n",
    "\n",
    "# convert to a pytorch tensor\n",
    "data = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).float()\n",
    "\n",
    "# show the data\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'bs')\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'ko')\n",
    "plt.title('The qwerties!')\n",
    "plt.xlabel('qwerty dimension 1')\n",
    "plt.ylabel('qwerty dimension 2')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inspect types\n",
    "print(type(data_np))\n",
    "print(np.shape(data_np))\n",
    "print(' ')\n",
    "\n",
    "print(type(data))\n",
    "print(np.shape(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build the model\n",
    "ANNclassify = nn.Sequential(\n",
    "    nn.Linear(2,1),   # input layer\n",
    "    nn.ReLU(),        # activation unit\n",
    "    nn.Linear(1,1),   # output unit\n",
    "    nn.Sigmoid(),     # final activation unit (here for conceptual reasons; in practice, better to use BCEWithLogitsLoss)\n",
    "      )\n",
    "\n",
    "ANNclassify"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# other model features\n",
    "\n",
    "learningRate = .01\n",
    "\n",
    "# loss function\n",
    "lossfun = nn.BCELoss()\n",
    "# Note: You'll learn in the \"Metaparameters\" section that it's better to use BCEWithLogitsLoss, but this is OK for now.\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(ANNclassify.parameters(),lr=learningRate)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the model\n",
    "numepochs = 1000\n",
    "losses = torch.zeros(numepochs)\n",
    "\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # forward pass\n",
    "  yHat = ANNclassify(data)\n",
    "\n",
    "  # compute loss\n",
    "  loss = lossfun(yHat,labels)\n",
    "  losses[epochi] = loss\n",
    "\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "while accuracy < 90:\n",
    "  # forward pass\n",
    "  yHat = ANNclassify(data)\n",
    "\n",
    "  # compute loss\n",
    "  loss = lossfun(yHat,labels)\n",
    "  #losses[epochi] = loss\n",
    "\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  predictions = ANNclassify(data)\n",
    "\n",
    "  predlabels = predictions>.5\n",
    "\n",
    "  # find errors\n",
    "  misclassified = np.where(predlabels != labels)[0]\n",
    "\n",
    "  # total accuracy\n",
    "  accuracy = 100-100*len(misclassified)/(2*nPerClust)\n",
    "  print(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show the losses\n",
    "\n",
    "plt.plot(losses.detach(),'o',markerfacecolor='w',linewidth=.1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute the predictions\n",
    "\n",
    "# manually compute losses\n",
    "# final forward pass\n",
    "predictions = ANNclassify(data)\n",
    "\n",
    "predlabels = predictions>.5\n",
    "\n",
    "# find errors\n",
    "misclassified = np.where(predlabels != labels)[0]\n",
    "\n",
    "# total accuracy\n",
    "totalacc = 100-100*len(misclassified)/(2*nPerClust)\n",
    "\n",
    "print('Final accuracy: %g%%' %totalacc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the labeled data\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(data[misclassified,0] ,data[misclassified,1],'rx',markersize=12,markeredgewidth=3)\n",
    "plt.plot(data[np.where(~predlabels)[0],0],data[np.where(~predlabels)[0],1],'bs')\n",
    "plt.plot(data[np.where(predlabels)[0],0] ,data[np.where(predlabels)[0],1] ,'ko')\n",
    "\n",
    "plt.legend(['Misclassified','blue','black'],bbox_to_anchor=(1,1))\n",
    "plt.title(f'{totalacc}% correct')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Additional explorations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) It is common in DL to train the model for a specified number of epochs. But you can also train until\n",
    "#    the model reaches a certain accuracy criterion. Re-write the code so that the model continues training\n",
    "#    until it reaches 90% accuracy.\n",
    "#    What would happen if the model falls into a local minimum and never reaches 90% accuracy? Yikes! You can\n",
    "#    force-quit a process in google-colab by clicking on the top-left 'play' button of a code cell.\n",
    "#\n",
    "# 2) It is intuitive that the model can reach 100% accuracy if the qwerties are more separable. Modify the\n",
    "#    qwerty-generating code to get the model to have 100% classification accuracy.\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pml6nCTcAMWC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 1) It is common in DL to train the model for a specified number of epochs. But you can also train until\n",
    "#    the model reaches a certain accuracy criterion. Re-write the code so that the model continues training\n",
    "#    until it reaches 90% accuracy.\n",
    "#    What would happen if the model falls into a local minimum and never reaches 90% accuracy? Yikes! You can\n",
    "#    force-quit a process in google-colab by clicking on the top-left 'play' button of a code cell.\n",
    "#\n",
    "# 2) It is intuitive that the model can reach 100% accuracy if the qwerties are more separable. Modify the\n",
    "#    qwerty-generating code to get the model to have 100% classification accuracy.\n",
    "#"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}